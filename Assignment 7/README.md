The assignment involves writing a gradient boost machine from scratch for some test data set.

(hint - the colab and article linked in https://docs.google.com/presentation/d/1tX64XE-_JKJXUgmPqOKieY5Ibe9HKWSVXOBSeGnzeL4/edit#slide=id.ga2af525914_0_6970 (Links to an external site.))

Please submit the colab github link with executed results.

Extra credits :

For all, see https://docs.google.com/presentation/d/1tX64XE-_JKJXUgmPqOKieY5Ibe9HKWSVXOBSeGnzeL4/edit#slide=id.p slide for hints and links to samples (Links to an external site.)

(you can try with gpu as well as grid search for hyper parameters as well if you want to delve deeper)

a) do a simple colab with some kaggle data set on xgboost machine - do gridsearch on hyperparams if possible

b) do a simple colab with some kaggle data set on catboost (ideally using gpu) - do gridsearch on hyperparams if possible

c) do a simple colab with some kaggle data set on lightgbm - do gridsearch on hyperparams if possible

d) do a simple colab with detailed visualization of results (see https://www.tensorflow.org/tutorials/estimator/boosted_trees_model_understanding (Links to an external site.))  with some kaggle data set on tensorflow boosted trees (tfbt) - do gridsearch on hyperparams if possible

e) repeat the colab code to make it work on sparkml - check the code for the chapter https://docs.google.com/presentation/d/1tX64XE-_JKJXUgmPqOKieY5Ibe9HKWSVXOBSeGnzeL4/edit#slide=id.ga2af525914_0_5137 (Links to an external site.) - and try out and showcase in code.  - do gridsearch on hyperparams if possible
